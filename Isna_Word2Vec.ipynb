{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFPyLOQMj5NB"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImxFOAOZjpLu",
        "outputId": "0034997d-7d03-482d-c797-244c0de43916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 : read_isna_content function"
      ],
      "metadata": {
        "id": "A2SxlavJ0nPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the read_isna_content function**"
      ],
      "metadata": {
        "id": "P6s8quak1YTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_isna_content(corpus_file):\n",
        "  # Read the CSV file\n",
        "  df = pd.read_csv(corpus_file, header=None, error_bad_lines=False)    # Ignor Cells with more than one column in each row\n",
        "\n",
        "  # Extract news text from the 3rd, 10th, 17th, ... rows\n",
        "  news_text_list = df.iloc[2::7, 0].astype(str).tolist()\n",
        "\n",
        "  # Concatenate the news texts into a single string\n",
        "  all_news_text = ' '.join(news_text_list)\n",
        "\n",
        "  return all_news_text"
      ],
      "metadata": {
        "id": "0dO8iOsxxU3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"All_news_text\" string\n",
        "corpus_file_path = 'persica.csv'\n",
        "all_news_text = read_isna_content(corpus_file_path)\n",
        "\n",
        "# Print the first 500 characters of the concatenated news text as a sample\n",
        "print(all_news_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPg_G09AAW-K",
        "outputId": "1a5d305a-1389-41da-9a69-0b108a051bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-78e3514b96e5>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(corpus_file, header=None, error_bad_lines=False)    # Ignor Cells with more than one column in each row\n",
            "Skipping line 1081: expected 2 fields, saw 8\n",
            "Skipping line 2852: expected 2 fields, saw 7\n",
            "Skipping line 6562: expected 2 fields, saw 3\n",
            "Skipping line 7514: expected 2 fields, saw 3\n",
            "Skipping line 7633: expected 2 fields, saw 4\n",
            "Skipping line 17846: expected 2 fields, saw 3\n",
            "Skipping line 18462: expected 2 fields, saw 3\n",
            "Skipping line 18889: expected 2 fields, saw 3\n",
            "Skipping line 24097: expected 2 fields, saw 3\n",
            "Skipping line 24125: expected 2 fields, saw 5\n",
            "Skipping line 25413: expected 2 fields, saw 4\n",
            "Skipping line 26064: expected 2 fields, saw 4\n",
            "Skipping line 26638: expected 2 fields, saw 5\n",
            "Skipping line 26904: expected 2 fields, saw 5\n",
            "Skipping line 27975: expected 2 fields, saw 6\n",
            "Skipping line 28780: expected 2 fields, saw 4\n",
            "Skipping line 30397: expected 2 fields, saw 6\n",
            "Skipping line 31545: expected 2 fields, saw 3\n",
            "Skipping line 31587: expected 2 fields, saw 3\n",
            "Skipping line 32126: expected 2 fields, saw 6\n",
            "Skipping line 32854: expected 2 fields, saw 18\n",
            "Skipping line 33764: expected 2 fields, saw 4\n",
            "Skipping line 34100: expected 2 fields, saw 6\n",
            "Skipping line 34583: expected 2 fields, saw 6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "وزير علوم در جمع استادان نمونه كشور گفت: از استادان نمونه كشور انتظار مي‌رود كه رويكرد دانايي محوري و گفتمان علمي را به عنوان يك بحث فرهنگي در دانشگاهها توسعه و رونق بخشند. به گزارش سرويس صنفي آموزشي خبرگزاري دانشجويان ايران (ايسنا)، دكتر محمد مهدي زاهدي در اولين مجمع عمومي استادان نمونه دانشگاه‌هاي سراسر كشور كه در دانشگاه تهران برگزار شد، افزود: توصيه ما در جهت تلاش براي دانايي محوري و توسعه گفتمان علمي به معني عدم تمايل به مباحث سياسي نيست؛ بلكه برعكس، دانشگاه بايد مهد چالشهاي گفتماني باشد ول\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the read_isna_content_to_list function**"
      ],
      "metadata": {
        "id": "4VClIniD3mKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_isna_content_to_list(corpus_file):\n",
        "  # Read the CSV file\n",
        "  df = pd.read_csv(corpus_file, header=None, error_bad_lines=False)\n",
        "\n",
        "  # Extract news text from the 3rd, 10th, 17th, ... rows\n",
        "  news_text_list = df.iloc[2::7, 0].astype(str).tolist()\n",
        "\n",
        "  return news_text_list"
      ],
      "metadata": {
        "id": "MBrZLu2GljlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\"news_text_list\" list\n",
        "corpus_file_path = 'persica.csv'\n",
        "news_text_list = read_isna_content_to_list(corpus_file_path)\n",
        "\n",
        "# Print the first few news texts as a sample\n",
        "for i, news_text in enumerate(news_text_list[:5]):\n",
        "    print(f\"News {i + 1}: {news_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkHMMm_cxdYK",
        "outputId": "b488e126-9e0a-4c33-d740-07e3ffa8a805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-334d64660bf1>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(corpus_file, header=None, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News 1: وزير علوم در جمع استادان نمونه كشور گفت: از استادان نمونه كشور انتظار مي‌رود كه رويكرد دانايي محوري و گفتمان علمي را به عنوان يك بحث فرهنگي در دانشگاهها توسعه و رونق بخشند. به گزارش سرويس صنفي آموزشي خبرگزاري دانشجويان ايران (ايسنا)، دكتر محمد مهدي زاهدي در اولين مجمع عمومي استادان نمونه دانشگاه‌هاي سراسر كشور كه در دانشگاه تهران برگزار شد، افزود: توصيه ما در جهت تلاش براي دانايي محوري و توسعه گفتمان علمي به معني عدم تمايل به مباحث سياسي نيست؛ بلكه برعكس، دانشگاه بايد مهد چالشهاي گفتماني باشد ولي اين امر، بدان معني نيست كه دانشگاه، ابزار دست سياسيون قرار بگيرد. وي تأكيد كرد: دانشگاه نه تنها نبايد تحت تأثير القائات سياسي قرار بگيرد؛ بلكه بايد خط دهنده و برنامه‌ريز جريانات سياسي باشد و مهمترين عنصر پياده شدن اين آرمان، دانشجويان و اعضاي هيات علمي دانشگاهها و در رأس آنها استادان نمونه هستند. وزير علوم با ذكر اين نكته كه در جامعه اطلاعاتي نمي‌توان هيچ تفكري را با تهديد و ارعاب حاكم كرد، افزود: اگر چه دانشگاهها بايد پرچمدار كرسيهاي آزاد انديشي و حاكميت دانايي محوري باشند، بايد توجه داشته باشند كه ناخودآگاه تحت تأثير جوسازيها و القائات رسانه‌ها قرار نگيرند. دكتر زاهدي سپس به اقدامات انجام شده در جهت ارتقاي جايگاه استادان نمونه اشاره كرد و گفت: در بنياد نخبگان، استادان نمونه از مصاديق نخبگان شناخته شدند و اين امر به لحاظ معنوي، اهميت ويژهاي دارد. در شوراي عالي انقلاب فرهنگي نيز براي اعضاي هيأت علمي با مرتبه علمي \"استاد تمامي\"، بويژه استادان نمونه تسهيلات مناسبي در نظر گرفته شده كه اميدوارم بزودي تصويب شود. وي افزود: همچنين قرار است با تصويب در هيأت امناي دانشگاهها و افزايش سن بازنشستگي استادان نمونه از 65 به 70 سال، دانشگاهها بتوانند از توان و ظرفيت علمي استادان نمونه، حداكثر استفاده را بكنند. وزير علوم در ادامه سپس از استادان نمونه خواست، در تعريف و تعيين شاخصهاي لازم براي انتخاب \"استاد نمونه\" بازنگري كنند و توان استادان در ترويج فرهنگ علمي در دانشگاه را در كنار توان آموزشي و پژوهشي آنان، به عنوان يك شاخص در نظر بگيرند. دكتر زاهدي در پايان قول داد كه مشاوره‌ها و راهنماييها كه از اطاق فكر استادان نمونه بيرون بيايد، با وسواس و دقت، در تصميم گيريها لحاظ شود.\n",
            "\n",
            "News 2: به گزارش سرويس صنفي آموزشي خبرگزاري دانشجويان ايران (ايسنا)، در اين برنامه كه به منظور تاسيس و انتخابات جامعه دانش‌آموختگان سوره برگزار مي‌شود جمعي از مسئولان و مديران سازمان تبليغات اسلامي، مديران حوزه هنري، مديران موسسه آموزش عالي سوره و همچنين جمعي از هنرمندان، استادان و اعضاي هيات علمي اين موسسه حضور دارند. همچنين در اين برنامه از جمعي از دانش آموختگان نمونه و استادان پيشكسوت اين موسسه تقدير مي‌شود. اجراي برنامه‌هاي موسيقي، تئاتر و نمايشگاهي از فعاليت‌هاي دانشجويان در زمينه‌هاي فرهنگي و هنري در گذشته و حال و همچنين غرفه‌هاي عكس يادگاري و ذكر خاطره‌اي از درگذشتگان سوره از جمله برنامه‌هاي جنبي اين گردهمايي مي‌باشد.\n",
            "\n",
            "News 3: نتايج آزمون دوره‌هاي فراگير مقاطع كارشناسي و كارشناسي ارشد دانشگاه پيام‌نور اعلام شد. به گزارش سرويس آموزشي خبرگزاري دانشجويان ايران (ايسنا)، اسامي پذيرفته‌شدگان آزمون نوبت چهارم دوره‌هاي فراگير در مقطع كارشناسي و نوبت سوم در مقطع كارشناسي ارشد دانشگاه پيام‌نور از طريق سايت دانشگاه به آدرس www.pnu.ac.ir اعلام شد. همچنين نتايج مشروطين اسفند ماه 82 كه درس مشروطي خود را در آزمون مرداد ماه 83 امتحان داده‌اند، متعاقبا اعلام خواهد شد. دانشگاه پيام نور همچنين با صدور اطلاعيه‌اي اعلام كرد: دانشگاه هيچ مجوزي براي هيچ موسسه‌اي اعم از دولتي،‌خصوصي، فرهنسگراها به منظور ثبت نام، تشكيل كلاس‌هاي رفع اشكال گروهي، حل مسائل و غيره صادر نكرده است و چنين موسساتي با اين دانشگاه ارتباطي ندارد.\n",
            "\n",
            "News 4: nan\n",
            "\n",
            "News 5: محمدتقي علوي يزدي، مجري اين طرح پژوهشي در اين‌باره به خبرنگار آموزشي ايسنا، گفت: نتايج به دست آمده نشان مي‌دهد كه اولا فرضيه اصلي براي ‌٧٠ درصد جامعه مورد بررسي مورد تاييد است و مهمترين عوامل موفقيت، وضعيت اقتصادي خوب خانواده، تحصيلات بالاي والدين بوده و مخصوصا مادران فرهنگي و شاغل توانسته‌اند موفقترين افراد را به جامعه اسلامي تحويل دهند. وي تصريح كرد: در مورد ‌٣٠ درصد افراد ناموفق مشخص گرديد كه شرط موفقيت تحصيلي و اجتماعي، تنها داشتن استعداد يادگيري نيست بلكه دو عامل بازدارنده بيروين و دروني مي تواند استعدادها را ضايع نمايند، وجود عوامل بازدارنده بيروني يعني ضعف اقتصادي، جو نامناسب عاطفي خانواده و موقعيت بد جغرافيايي باعث شده است كه تعدادي از معدل بيست‌ها حتي نتوانند مقطع ابتدايي را به پايان برسانند. وي، عدم استعداد يادگيري در سطح عالي، عدم علاقه به ادامه تحصيل براي كسب مدارج علمي را از جمله عوامل بازدارنده دروني عنوان كرد و گفت: تاكيد ما بر معدل بيست‌هايي بوده است كه با عدم استعداد يادگيري در سطح عالي بنا به دلايل معرفي شده با اخذ نمرات ‌٢٠ غير واقعي به گروه معدل بيست‌ها پيوسته‌اند كه در طول ‌١٤ سال گذشته بر تعداد اين معدل بيست‌ها به طور بي‌رويه‌اي اضافه شده است و اين در حالي است كه در يكي از شهرهاي تابعه استان يزد درصد اين افزايش حدود ‌٨٠/٨٦ درصد بوده است. اين محقق تاكيد دارد: مطالعه زندگي معدل بيست‌هاي ناموفق نشان مي دهد كه نه تنها از زندگي، تحصيل و اجتماعي خود احساس رضايت ندارند بلكه در مواردي طرز تفكر آنان شبيه به افراد ناسازگار است، به همين دليل به والدين دانش آموزان مقطع ابتدايي، آموزگاران دبستاني، مشاوران مدارس راهنمايي، دبيران مقطع متوسطه و بالاخره مسوولين آموزش و پرورش پيشنهاد مي شود تا زماني كه تست‌هاي استاندار جهت تشخيص واقعي استعدادها در مدارس وجود ندارد، منطقي‌ترين روش ارزشيابي آن است كه به دانش آموزان خود نمرات واقعي بدهند. علوي يزدي در پايان تصريح كرد: اين پيشنهاد باعث مي‌گردد تا جوانان جامعه جوان ما‌، واقع گراتر رشد نموده و يك تصوير ذهني واقعي از خود داشته باشند و بديهي است كه انسان‌هاي واقع‌گرا از زندگي واقعي خود بيشتر احسا رضايت مي نمايند.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 1081: expected 2 fields, saw 8\n",
            "Skipping line 2852: expected 2 fields, saw 7\n",
            "Skipping line 6562: expected 2 fields, saw 3\n",
            "Skipping line 7514: expected 2 fields, saw 3\n",
            "Skipping line 7633: expected 2 fields, saw 4\n",
            "Skipping line 17846: expected 2 fields, saw 3\n",
            "Skipping line 18462: expected 2 fields, saw 3\n",
            "Skipping line 18889: expected 2 fields, saw 3\n",
            "Skipping line 24097: expected 2 fields, saw 3\n",
            "Skipping line 24125: expected 2 fields, saw 5\n",
            "Skipping line 25413: expected 2 fields, saw 4\n",
            "Skipping line 26064: expected 2 fields, saw 4\n",
            "Skipping line 26638: expected 2 fields, saw 5\n",
            "Skipping line 26904: expected 2 fields, saw 5\n",
            "Skipping line 27975: expected 2 fields, saw 6\n",
            "Skipping line 28780: expected 2 fields, saw 4\n",
            "Skipping line 30397: expected 2 fields, saw 6\n",
            "Skipping line 31545: expected 2 fields, saw 3\n",
            "Skipping line 31587: expected 2 fields, saw 3\n",
            "Skipping line 32126: expected 2 fields, saw 6\n",
            "Skipping line 32854: expected 2 fields, saw 18\n",
            "Skipping line 33764: expected 2 fields, saw 4\n",
            "Skipping line 34100: expected 2 fields, saw 6\n",
            "Skipping line 34583: expected 2 fields, saw 6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 : Normalize function"
      ],
      "metadata": {
        "id": "woCymS9m3yi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the normalize function**"
      ],
      "metadata": {
        "id": "6-oWKelwBCln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_text):\n",
        "  # Define a regular expression for tokenization\n",
        "  persian_word_tokenizer = nltk.RegexpTokenizer(r'\\w+|[،؛:.؟]')\n",
        "\n",
        "  # Tokenize the input text using the custom tokenizer\n",
        "  tokens = persian_word_tokenizer.tokenize(input_text)\n",
        "\n",
        "  # Add space before and after each token\n",
        "  spaced_tokens = [' ' + token + ' ' for token in tokens]\n",
        "\n",
        "  # Concatenate the spaced tokens into a single string\n",
        "  normalized_text = ''.join(spaced_tokens)\n",
        "\n",
        "  # Replace extra spaces with a single space\n",
        "  normalized_text = re.sub(r'\\s+', ' ', normalized_text)\n",
        "\n",
        "  # Unify different codings for Persian letters\n",
        "  normalized_text = normalized_text.replace('ي', 'ی').replace('ك', 'ک').replace('ئ', 'ی')\n",
        "\n",
        "  return normalized_text"
      ],
      "metadata": {
        "id": "yY2C6o4wA7Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalized_news_text string**"
      ],
      "metadata": {
        "id": "fnlXdsPeBITW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized_news_text string\n",
        "normalized_news_text = normalize(all_news_text)\n",
        "\n",
        "# Print the first 500 characters of the normalized text as a sample\n",
        "print(normalized_news_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC35jYNz8cIN",
        "outputId": "36345059-4dc8-4bf0-ee1b-1a6f4357b13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " وزیر علوم در جمع استادان نمونه کشور گفت : از استادان نمونه کشور انتظار می رود که رویکرد دانایی محوری و گفتمان علمی را به عنوان یک بحث فرهنگی در دانشگاهها توسعه و رونق بخشند . به گزارش سرویس صنفی آموزشی خبرگزاری دانشجویان ایران ایسنا ، دکتر محمد مهدی زاهدی در اولین مجمع عمومی استادان نمونه دانشگاه های سراسر کشور که در دانشگاه تهران برگزار شد ، افزود : توصیه ما در جهت تلاش برای دانایی محوری و توسعه گفتمان علمی به معنی عدم تمایل به مباحث سیاسی نیست ؛ بلکه برعکس ، دانشگاه باید مهد چالشهای گفتمانی ب\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 : segment_corpus function"
      ],
      "metadata": {
        "id": "5GTqiNuLIzZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the segment_corpus function**"
      ],
      "metadata": {
        "id": "sNLbExiDIzZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corpus_segment(normalized_text):\n",
        "  # Define the regex pattern for sentence segmentation\n",
        "  sentence_pattern = r'[.؛؟!]+'\n",
        "\n",
        "  # Split the normalized text into sentences\n",
        "  sentences = re.split(sentence_pattern, normalized_text)\n",
        "\n",
        "  # Convert string to the list of sentences\n",
        "  sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "q-ZtuVCYIzZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sentences_list**"
      ],
      "metadata": {
        "id": "AoNsCaNGIzZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentences list\n",
        "sentences_list = corpus_segment(normalized_news_text)\n",
        "\n",
        "# Print the first few sentences as a sample\n",
        "for i, sentence in enumerate(sentences_list[:5]):\n",
        "    print(f\"Sentence {i + 1}: {sentence}\\n\")\n",
        "\n",
        "print( \"Number of sentences in list:\", len(sentences_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7318eefd-afaf-43d8-ca16-0a115738fe29",
        "id": "KZS47S1fIzZG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: وزیر علوم در جمع استادان نمونه کشور گفت : از استادان نمونه کشور انتظار می رود که رویکرد دانایی محوری و گفتمان علمی را به عنوان یک بحث فرهنگی در دانشگاهها توسعه و رونق بخشند\n",
            "\n",
            "Sentence 2: به گزارش سرویس صنفی آموزشی خبرگزاری دانشجویان ایران ایسنا ، دکتر محمد مهدی زاهدی در اولین مجمع عمومی استادان نمونه دانشگاه های سراسر کشور که در دانشگاه تهران برگزار شد ، افزود : توصیه ما در جهت تلاش برای دانایی محوری و توسعه گفتمان علمی به معنی عدم تمایل به مباحث سیاسی نیست\n",
            "\n",
            "Sentence 3: بلکه برعکس ، دانشگاه باید مهد چالشهای گفتمانی باشد ولی این امر ، بدان معنی نیست که دانشگاه ، ابزار دست سیاسیون قرار بگیرد\n",
            "\n",
            "Sentence 4: وی تأکید کرد : دانشگاه نه تنها نباید تحت تأثیر القایات سیاسی قرار بگیرد\n",
            "\n",
            "Sentence 5: بلکه باید خط دهنده و برنامه ریز جریانات سیاسی باشد و مهمترین عنصر پیاده شدن این آرمان ، دانشجویان و اعضای هیات علمی دانشگاهها و در رأس آنها استادان نمونه هستند\n",
            "\n",
            "Number of sentences in list: 8237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 : prepare_data function"
      ],
      "metadata": {
        "id": "Wl7seLmpM5n8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the prepare_data function**"
      ],
      "metadata": {
        "id": "WGIRyK20M5n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prepare(sentences_list):\n",
        "    # Tokenize each sentence into words\n",
        "    tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences_list]\n",
        "\n",
        "    return tokenized_sentences"
      ],
      "metadata": {
        "id": "XfSRCJzuM5n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**word_tokenized_sentences_list**"
      ],
      "metadata": {
        "id": "FXIhsMAxM5n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word_tokenized_sentences_list\n",
        "word_tokenized_sentences_list = data_prepare(sentences_list)\n",
        "\n",
        "# Print the first few tokenized sentences as a sample\n",
        "for i, tokenized_sentence in enumerate(word_tokenized_sentences_list[:5]):\n",
        "    print(f\"Tokenized Sentence {i + 1}: {tokenized_sentence}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f60be90-f6b5-4fc5-ba02-7b783df14208",
        "id": "t0WYGOj1M5oA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentence 1: ['وزیر', 'علوم', 'در', 'جمع', 'استادان', 'نمونه', 'کشور', 'گفت', ':', 'از', 'استادان', 'نمونه', 'کشور', 'انتظار', 'می', 'رود', 'که', 'رویکرد', 'دانایی', 'محوری', 'و', 'گفتمان', 'علمی', 'را', 'به', 'عنوان', 'یک', 'بحث', 'فرهنگی', 'در', 'دانشگاهها', 'توسعه', 'و', 'رونق', 'بخشند']\n",
            "\n",
            "Tokenized Sentence 2: ['به', 'گزارش', 'سرویس', 'صنفی', 'آموزشی', 'خبرگزاری', 'دانشجویان', 'ایران', 'ایسنا', '،', 'دکتر', 'محمد', 'مهدی', 'زاهدی', 'در', 'اولین', 'مجمع', 'عمومی', 'استادان', 'نمونه', 'دانشگاه', 'های', 'سراسر', 'کشور', 'که', 'در', 'دانشگاه', 'تهران', 'برگزار', 'شد', '،', 'افزود', ':', 'توصیه', 'ما', 'در', 'جهت', 'تلاش', 'برای', 'دانایی', 'محوری', 'و', 'توسعه', 'گفتمان', 'علمی', 'به', 'معنی', 'عدم', 'تمایل', 'به', 'مباحث', 'سیاسی', 'نیست']\n",
            "\n",
            "Tokenized Sentence 3: ['بلکه', 'برعکس', '،', 'دانشگاه', 'باید', 'مهد', 'چالشهای', 'گفتمانی', 'باشد', 'ولی', 'این', 'امر', '،', 'بدان', 'معنی', 'نیست', 'که', 'دانشگاه', '،', 'ابزار', 'دست', 'سیاسیون', 'قرار', 'بگیرد']\n",
            "\n",
            "Tokenized Sentence 4: ['وی', 'تأکید', 'کرد', ':', 'دانشگاه', 'نه', 'تنها', 'نباید', 'تحت', 'تأثیر', 'القایات', 'سیاسی', 'قرار', 'بگیرد']\n",
            "\n",
            "Tokenized Sentence 5: ['بلکه', 'باید', 'خط', 'دهنده', 'و', 'برنامه', 'ریز', 'جریانات', 'سیاسی', 'باشد', 'و', 'مهمترین', 'عنصر', 'پیاده', 'شدن', 'این', 'آرمان', '،', 'دانشجویان', 'و', 'اعضای', 'هیات', 'علمی', 'دانشگاهها', 'و', 'در', 'رأس', 'آنها', 'استادان', 'نمونه', 'هستند']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5 : Train Word2Vec embedding"
      ],
      "metadata": {
        "id": "mgZl6zRSYN9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and save Word2Vec embedding**"
      ],
      "metadata": {
        "id": "1bBrwp6HYN9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 parameters\n",
        "size1 = 50\n",
        "window1 = 5\n",
        "negative1 = 5\n",
        "\n",
        "# Model 2 parameters\n",
        "size2 = 100\n",
        "window2 = 5\n",
        "negative2 = 5\n",
        "\n",
        "# Train and save Model 1\n",
        "model1 = Word2Vec(sentences=word_tokenized_sentences_list, vector_size=size1, window=window1, min_count=2, negative=negative1)\n",
        "model1.save(\"word2vec_model_size50_window5_negative5.model\")\n",
        "\n",
        "# Train and save Model 2\n",
        "model2 = Word2Vec(sentences=word_tokenized_sentences_list, vector_size=size2, window=window2, min_count=2, negative=negative2)\n",
        "model2.save(\"word2vec_model_size100_window5_negative5.model\")"
      ],
      "metadata": {
        "id": "N4BvsuhtYN9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load models**"
      ],
      "metadata": {
        "id": "GjFJCVyvYN9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model 1\n",
        "loaded_model1 = Word2Vec.load(\"word2vec_model_size50_window5_negative5.model\")\n",
        "\n",
        "# Load Model 2\n",
        "loaded_model2 = Word2Vec.load(\"word2vec_model_size100_window5_negative5.model\")"
      ],
      "metadata": {
        "id": "oWtQ_wqOYN9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6 : Evaluation _ Finding the most similar words"
      ],
      "metadata": {
        "id": "kBZuE1hwayiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Find the most similar words**"
      ],
      "metadata": {
        "id": "mdXmtvANayiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Words that want to find similarities\n",
        "example_words = ['ایران', 'دانشگاه', 'دولت', 'انقلاب', 'قانون']\n",
        "\n",
        "# Find similarities for each word in each model\n",
        "similarities_model1 = {word: model1.wv.similar_by_word(word) for word in example_words}\n",
        "similarities_model2 = {word: model2.wv.similar_by_word(word) for word in example_words}\n",
        "\n",
        "# Print similarities for Model 1\n",
        "print(\"Similarities for Model 1:\")\n",
        "for word, similar_words in similarities_model1.items():\n",
        "    print(f\"{word}: {similar_words}\")\n",
        "\n",
        "# Print similarities for Model 2\n",
        "print(\"\\nSimilarities for Model 2:\")\n",
        "for word, similar_words in similarities_model2.items():\n",
        "    print(f\"{word}: {similar_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQz87JxyayiU",
        "outputId": "8abfd1e9-a88d-4df0-e841-635f3ecfe2f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarities for Model 1:\n",
            "ایران: [('خبرگزاری', 0.9440688490867615), ('خبرنگار', 0.9320939183235168), ('گزارش', 0.9265751242637634), ('سرویس', 0.9212666153907776), ('دانشجویان', 0.9066506624221802), ('الملل', 0.8970072269439697), ('آموزشی', 0.8869150280952454), ('ایسنا', 0.8850845098495483), ('سلف', 0.8828346133232117), ('آیندگان', 0.8818368911743164)]\n",
            "دانشگاه: [('پزشکی', 0.9103058576583862), ('تهران', 0.8979265093803406), ('علوم', 0.8916412591934204), ('کوی', 0.8537211418151855), ('دانشکده', 0.8416251540184021), ('مامایی', 0.8387202620506287), ('معاونت', 0.8216869831085205), ('تحقیقات', 0.8154574632644653), ('سازمان', 0.8113913536071777), ('دانشجویی', 0.8100393414497375)]\n",
            "دولت: [('کشورهای', 0.9405451416969299), ('عدم', 0.9400185346603394), ('هدف', 0.9307111501693726), ('اطلاع', 0.9306146502494812), ('روشنی', 0.9296970963478088), ('ندارد', 0.9278123378753662), ('پزشکان', 0.9271220564842224), ('ویژه', 0.9263136386871338), ('آمریکا', 0.9252523183822632), ('پیشنهادی', 0.9251922965049744)]\n",
            "انقلاب: [('جمهوری', 0.8729013204574585), ('پیروزی', 0.827246904373169), ('بنیانگذار', 0.8093949556350708), ('متون', 0.8056132793426514), ('اسلامی', 0.7973484992980957), ('یکی', 0.7924334406852722), ('قاموس', 0.7828793525695801), ('پیرو', 0.7823607325553894), ('سوی', 0.7777643203735352), ('بختیاری', 0.7768988013267517)]\n",
            "قانون: [('اساسی', 0.9739668965339661), ('اصل', 0.9414584040641785), ('انحلال', 0.9379360675811768), ('ماده', 0.9368138313293457), ('رفراندوم', 0.9348133206367493), ('مجازات', 0.9335033297538757), ('خبرگان', 0.9318707585334778), ('نمایندگان', 0.931769073009491), ('مبتنی', 0.9317556023597717), ('لوایح', 0.931534469127655)]\n",
            "\n",
            "Similarities for Model 2:\n",
            "ایران: [('دانشجویان', 0.9602976441383362), ('خبرگزاری', 0.9562033414840698), ('گزارش', 0.9359211921691895), ('خبرنگار', 0.9354157447814941), ('سرویس', 0.9303839206695557), ('نقل', 0.9071599245071411), ('آموزشی', 0.9056140780448914), ('ایسنا', 0.9021547436714172), ('داستانی', 0.9019118547439575), ('صنفی', 0.8980873227119446)]\n",
            "دانشگاه: [('تهران', 0.9198854565620422), ('پزشکی', 0.9070498943328857), ('مامایی', 0.8953016400337219), ('کوی', 0.8707370758056641), ('علوم', 0.8693382740020752), ('استاد', 0.848997950553894), ('هیات', 0.8355409502983093), ('مدرس', 0.8322067856788635), ('روسای', 0.8319665193557739), ('رضاشاه', 0.8245861530303955)]\n",
            "دولت: [('هدف', 0.965815007686615), ('کارآفرینی', 0.9637064933776855), ('آمریکا', 0.9593786001205444), ('عنایت', 0.9587954878807068), ('دریافت', 0.9572592973709106), ('نیروی', 0.9558790922164917), ('انگلیس', 0.9550134539604187), ('مغایر', 0.9549117684364319), ('خبری', 0.9543554782867432), ('کشورهای', 0.9540888071060181)]\n",
            "انقلاب: [('جمهوری', 0.8970299959182739), ('پیروزی', 0.8514193892478943), ('اسلامی', 0.8298840522766113), ('کبیر', 0.8131797313690186), ('رهبر', 0.8008227944374084), ('امیدوارم', 0.8005953431129456), ('ریاست', 0.7988959550857544), ('متون', 0.7977727651596069), ('بنیانگذار', 0.7939213514328003), ('موتلفه', 0.7935503125190735)]\n",
            "قانون: [('اساسی', 0.9757733345031738), ('اصل', 0.9720919728279114), ('ماده', 0.9704213738441467), ('اصول', 0.9633781313896179), ('میوه', 0.9623696804046631), ('چون', 0.9620534777641296), ('رفراندوم', 0.9619699716567993), ('والفجر', 0.9615151882171631), ('تصمیمات', 0.9614880681037903), ('داری', 0.9614711403846741)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7 : Evaluation _ Finding the average cosine similarity for antonym words"
      ],
      "metadata": {
        "id": "0obDENWCfZcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7) Find the average cosine similarities for both models**"
      ],
      "metadata": {
        "id": "Vp5BNdzufZcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained models\n",
        "model1 = Word2Vec.load(\"word2vec_model_size50_window5_negative5.model\")\n",
        "model2 = Word2Vec.load(\"word2vec_model_size100_window5_negative5.model\")\n",
        "\n",
        "# Read the antonyms file and extract word pairs\n",
        "with open(\"ML-NLP-antonyms.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    antonyms_data = [line.strip().split('،') for line in file]\n",
        "\n",
        "# Calculate cosine similarity for each word pair in each model\n",
        "similarities_model1 = []\n",
        "similarities_model2 = []\n",
        "words_not_found = set()\n",
        "\n",
        "for word1, word2 in antonyms_data:\n",
        "    try:\n",
        "        embedding1 = model1.wv[word1]\n",
        "        embedding2 = model1.wv[word2]\n",
        "        similarity_model1 = cosine_similarity([embedding1, embedding2])[0, 1]\n",
        "        similarities_model1.append(similarity_model1)\n",
        "        print(f\"Cosine Similarity for '{word1}' and '{word2}' in Model 1: {similarity_model1}\")\n",
        "    except KeyError:\n",
        "        words_not_found.add(word1)\n",
        "        words_not_found.add(word2)\n",
        "        print(f\"The word '{word1}' or '{word2}' does not exist in Model 1\")\n",
        "\n",
        "    try:\n",
        "        embedding1 = model2.wv[word1]\n",
        "        embedding2 = model2.wv[word2]\n",
        "        similarity_model2 = cosine_similarity([embedding1, embedding2])[0, 1]\n",
        "        similarities_model2.append(similarity_model2)\n",
        "        print(f\"Cosine Similarity for '{word1}' and '{word2}' in Model 2: {similarity_model2}\")\n",
        "    except KeyError:\n",
        "        words_not_found.add(word1)\n",
        "        words_not_found.add(word2)\n",
        "        print(f\"The word '{word1}' or '{word2}' does not exist in Model 2\")\n",
        "\n",
        "# Print the \"does not exist\" message for each word\n",
        "for word in words_not_found:\n",
        "    print(f\"The word '{word}' does not exist in either Model 1 or Model 2\")\n",
        "\n",
        "# Calculate the average similarity for each model\n",
        "average_similarity_model1 = np.mean(similarities_model1) if similarities_model1 else None\n",
        "average_similarity_model2 = np.mean(similarities_model2) if similarities_model2 else None\n",
        "\n",
        "# Print the average similarities\n",
        "print(f\"\\nAverage Cosine Similarity for Model 1: {average_similarity_model1}\")\n",
        "print(f\"Average Cosine Similarity for Model 2: {average_similarity_model2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgjL4F5jh3Ek",
        "outputId": "ece72fec-f50e-4fb9-ffac-256526126921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'سواره' or 'پیاده' does not exist in Model 1\n",
            "The word 'سواره' or 'پیاده' does not exist in Model 2\n",
            "The word 'دانا' or 'نادان' does not exist in Model 1\n",
            "The word 'دانا' or 'نادان' does not exist in Model 2\n",
            "Cosine Similarity for 'دفاع' and 'حمله' in Model 1: 0.9500234723091125\n",
            "Cosine Similarity for 'دفاع' and 'حمله' in Model 2: 0.9558526277542114\n",
            "Cosine Similarity for 'درست' and 'غلط' in Model 1: 0.9673619270324707\n",
            "Cosine Similarity for 'درست' and 'غلط' in Model 2: 0.9848058819770813\n",
            "Cosine Similarity for 'خوب' and 'بد' in Model 1: 0.9715793132781982\n",
            "Cosine Similarity for 'خوب' and 'بد' in Model 2: 0.95875084400177\n",
            "Cosine Similarity for 'تشابه' and 'تضاد' in Model 1: 0.9275344014167786\n",
            "Cosine Similarity for 'تشابه' and 'تضاد' in Model 2: 0.9257665872573853\n",
            "Cosine Similarity for 'ورود' and 'خروج' in Model 1: 0.9059605598449707\n",
            "Cosine Similarity for 'ورود' and 'خروج' in Model 2: 0.9299143552780151\n",
            "Cosine Similarity for 'موافق' and 'مخالف' in Model 1: 0.9701758623123169\n",
            "Cosine Similarity for 'موافق' and 'مخالف' in Model 2: 0.9720229506492615\n",
            "Cosine Similarity for 'پیدا' and 'پنهان' in Model 1: 0.9209892749786377\n",
            "Cosine Similarity for 'پیدا' and 'پنهان' in Model 2: 0.9172444343566895\n",
            "The word 'آسوده' or 'مضطرب' does not exist in Model 1\n",
            "The word 'آسوده' or 'مضطرب' does not exist in Model 2\n",
            "Cosine Similarity for 'اول' and 'آخر' in Model 1: 0.941710352897644\n",
            "Cosine Similarity for 'اول' and 'آخر' in Model 2: 0.9383162260055542\n",
            "Cosine Similarity for 'آزاد' and 'اسیر' in Model 1: 0.7859106063842773\n",
            "Cosine Similarity for 'آزاد' and 'اسیر' in Model 2: 0.9397169947624207\n",
            "Cosine Similarity for 'آغاز' and 'پایان' in Model 1: 0.8080604672431946\n",
            "Cosine Similarity for 'آغاز' and 'پایان' in Model 2: 0.7744923233985901\n",
            "The word 'چاق' or 'لاغر' does not exist in Model 1\n",
            "The word 'چاق' or 'لاغر' does not exist in Model 2\n",
            "Cosine Similarity for 'زشت' and 'زیبا' in Model 1: 0.9097121357917786\n",
            "Cosine Similarity for 'زشت' and 'زیبا' in Model 2: 0.9579306840896606\n",
            "Cosine Similarity for 'خارج' and 'داخل' in Model 1: 0.9581353068351746\n",
            "Cosine Similarity for 'خارج' and 'داخل' in Model 2: 0.9668335914611816\n",
            "The word 'دم' or 'بازدم' does not exist in Model 1\n",
            "The word 'دم' or 'بازدم' does not exist in Model 2\n",
            "Cosine Similarity for 'خرید' and 'فروش' in Model 1: 0.9909110069274902\n",
            "Cosine Similarity for 'خرید' and 'فروش' in Model 2: 0.9955287575721741\n",
            "Cosine Similarity for 'پر' and 'خالی' in Model 1: 0.9727193713188171\n",
            "Cosine Similarity for 'پر' and 'خالی' in Model 2: 0.9944440722465515\n",
            "Cosine Similarity for 'سنگین' and 'سبک' in Model 1: 0.9722750186920166\n",
            "Cosine Similarity for 'سنگین' and 'سبک' in Model 2: 0.9774205684661865\n",
            "Cosine Similarity for 'پیر' and 'جوان' in Model 1: 0.9117351770401001\n",
            "Cosine Similarity for 'پیر' and 'جوان' in Model 2: 0.9477916955947876\n",
            "Cosine Similarity for 'دیر' and 'زود' in Model 1: 0.9369546175003052\n",
            "Cosine Similarity for 'دیر' and 'زود' in Model 2: 0.9557775259017944\n",
            "Cosine Similarity for 'خوب' and 'بد' in Model 1: 0.9715793132781982\n",
            "Cosine Similarity for 'خوب' and 'بد' in Model 2: 0.95875084400177\n",
            "The word 'فقیر' or 'پولدار' does not exist in Model 1\n",
            "The word 'فقیر' or 'پولدار' does not exist in Model 2\n",
            "Cosine Similarity for 'بیمار' and 'سالم' in Model 1: 0.9660005569458008\n",
            "Cosine Similarity for 'بیمار' and 'سالم' in Model 2: 0.9681662321090698\n",
            "Cosine Similarity for 'مرده' and 'زنده' in Model 1: 0.9358479976654053\n",
            "Cosine Similarity for 'مرده' and 'زنده' in Model 2: 0.9819937348365784\n",
            "Cosine Similarity for 'بزرگ' and 'کوچک' in Model 1: 0.9855467081069946\n",
            "Cosine Similarity for 'بزرگ' and 'کوچک' in Model 2: 0.9885928630828857\n",
            "Cosine Similarity for 'بلند' and 'کوتاه' in Model 1: 0.9865330457687378\n",
            "Cosine Similarity for 'بلند' and 'کوتاه' in Model 2: 0.9911330938339233\n",
            "Cosine Similarity for 'سیاه' and 'سفید' in Model 1: 0.9740789532661438\n",
            "Cosine Similarity for 'سیاه' and 'سفید' in Model 2: 0.9885131120681763\n",
            "Cosine Similarity for 'ساده' and 'پیچیده' in Model 1: 0.9642701745033264\n",
            "Cosine Similarity for 'ساده' and 'پیچیده' in Model 2: 0.9744794964790344\n",
            "The word 'بدمزه' or 'خوشمزه' does not exist in Model 1\n",
            "The word 'بدمزه' or 'خوشمزه' does not exist in Model 2\n",
            "Cosine Similarity for 'سرد' and 'گرم' in Model 1: 0.8061736226081848\n",
            "Cosine Similarity for 'سرد' and 'گرم' in Model 2: 0.7684353590011597\n",
            "Cosine Similarity for 'ناراحت' and 'خوشحال' in Model 1: 0.9354419112205505\n",
            "Cosine Similarity for 'ناراحت' and 'خوشحال' in Model 2: 0.8032790422439575\n",
            "Cosine Similarity for 'ناآگاه' and 'آگاه' in Model 1: 0.9621971845626831\n",
            "Cosine Similarity for 'ناآگاه' and 'آگاه' in Model 2: 0.9708920121192932\n",
            "The word 'ناامید' or 'امیدوار' does not exist in Model 1\n",
            "The word 'ناامید' or 'امیدوار' does not exist in Model 2\n",
            "The word 'گریان' or 'خندان' does not exist in Model 1\n",
            "The word 'گریان' or 'خندان' does not exist in Model 2\n",
            "Cosine Similarity for 'کم' and 'زیاد' in Model 1: 0.9881250858306885\n",
            "Cosine Similarity for 'کم' and 'زیاد' in Model 2: 0.9886084198951721\n",
            "Cosine Similarity for 'رکود' and 'رونق' in Model 1: 0.8941285610198975\n",
            "Cosine Similarity for 'رکود' and 'رونق' in Model 2: 0.9707867503166199\n",
            "Cosine Similarity for 'رفتن' and 'آمدن' in Model 1: 0.9847413897514343\n",
            "Cosine Similarity for 'رفتن' and 'آمدن' in Model 2: 0.9909159541130066\n",
            "Cosine Similarity for 'عشق' and 'نفرت' in Model 1: 0.7058258056640625\n",
            "Cosine Similarity for 'عشق' and 'نفرت' in Model 2: 0.890736997127533\n",
            "Cosine Similarity for 'آباد' and 'خراب' in Model 1: 0.8276011347770691\n",
            "Cosine Similarity for 'آباد' and 'خراب' in Model 2: 0.576171338558197\n",
            "The word 'خوشبخت' or 'بدبخت' does not exist in Model 1\n",
            "The word 'خوشبخت' or 'بدبخت' does not exist in Model 2\n",
            "Cosine Similarity for 'پس' and 'پیش' in Model 1: 0.7791308760643005\n",
            "Cosine Similarity for 'پس' and 'پیش' in Model 2: 0.8047401905059814\n",
            "Cosine Similarity for 'بالا' and 'پایین' in Model 1: 0.9888492822647095\n",
            "Cosine Similarity for 'بالا' and 'پایین' in Model 2: 0.9914781451225281\n",
            "Cosine Similarity for 'جلو' and 'عقب' in Model 1: 0.9865201115608215\n",
            "Cosine Similarity for 'جلو' and 'عقب' in Model 2: 0.9908886551856995\n",
            "Cosine Similarity for 'چپ' and 'راست' in Model 1: 0.9822403788566589\n",
            "Cosine Similarity for 'چپ' and 'راست' in Model 2: 0.9830513596534729\n",
            "Cosine Similarity for 'شمال' and 'جنوب' in Model 1: 0.9862972497940063\n",
            "Cosine Similarity for 'شمال' and 'جنوب' in Model 2: 0.9867545366287231\n",
            "Cosine Similarity for 'شرق' and 'غرب' in Model 1: 0.9868101477622986\n",
            "Cosine Similarity for 'شرق' and 'غرب' in Model 2: 0.9906908869743347\n",
            "The word 'پولدار' does not exist in either Model 1 or Model 2\n",
            "The word 'بدمزه' does not exist in either Model 1 or Model 2\n",
            "The word 'گریان' does not exist in either Model 1 or Model 2\n",
            "The word 'چاق' does not exist in either Model 1 or Model 2\n",
            "The word 'خندان' does not exist in either Model 1 or Model 2\n",
            "The word 'فقیر' does not exist in either Model 1 or Model 2\n",
            "The word 'بازدم' does not exist in either Model 1 or Model 2\n",
            "The word 'پیاده' does not exist in either Model 1 or Model 2\n",
            "The word 'دم' does not exist in either Model 1 or Model 2\n",
            "The word 'آسوده' does not exist in either Model 1 or Model 2\n",
            "The word 'خوشبخت' does not exist in either Model 1 or Model 2\n",
            "The word 'مضطرب' does not exist in either Model 1 or Model 2\n",
            "The word 'لاغر' does not exist in either Model 1 or Model 2\n",
            "The word 'ناامید' does not exist in either Model 1 or Model 2\n",
            "The word 'سواره' does not exist in either Model 1 or Model 2\n",
            "The word 'دانا' does not exist in either Model 1 or Model 2\n",
            "The word 'نادان' does not exist in either Model 1 or Model 2\n",
            "The word 'امیدوار' does not exist in either Model 1 or Model 2\n",
            "The word 'بدبخت' does not exist in either Model 1 or Model 2\n",
            "The word 'خوشمزه' does not exist in either Model 1 or Model 2\n",
            "\n",
            "Average Cosine Similarity for Model 1: 0.9315706491470337\n",
            "Average Cosine Similarity for Model 2: 0.938201904296875\n"
          ]
        }
      ]
    }
  ]
}